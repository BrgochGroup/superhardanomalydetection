{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dscribe.descriptors import SOAP, MBTR\n",
    "from ase.io import read\n",
    "from ase import Atoms\n",
    "from ase import neighborlist\n",
    "import ase.data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import os\n",
    "import spglib\n",
    "from asap3.analysis.rdf import RadialDistributionFunction\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch as th\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24025cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpdata = pk.load(open('mp0106_max5_all_structure.p', 'rb'))\n",
    "#len(mpdata)\n",
    "mptarget = pk.load(open('mp0106_max5_all_props.p', 'rb'))\n",
    "#len(mptarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e314da",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = set()\n",
    "for i in range(len(mpdata)):\n",
    "    species.update(mpdata[i].get_chemical_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbtr_lists = []\n",
    "\n",
    "for i in range(len(mpdata)):\n",
    "    species = set()\n",
    "    species.update(mpdata[i].get_chemical_symbols())\n",
    "    mbtr = MBTR(\n",
    "        species=species,\n",
    "        periodic=True,\n",
    "        k1={\n",
    "            \"geometry\": {\"function\": \"atomic_number\"},\n",
    "            \"grid\": {\"min\": 0, \"max\": 82, \"sigma\": 0.1, \"n\": 82},\n",
    "        },\n",
    "        k2={\n",
    "            \"geometry\": {\"function\": \"inverse_distance\"},\n",
    "            #\"grid\": {\"min\": 0.5, \"max\": 6, \"sigma\": 0.02, \"n\": 50},\n",
    "            \"grid\": {\"min\": 0, \"max\": 1, \"sigma\": 0.02, \"n\": 30},\n",
    "            \"weighting\": {\"function\": \"exp\", \"scale\": 1.0, \"threshold\": 1e-3},\n",
    "        },\n",
    "        k3={\n",
    "            \"geometry\": {\"function\": \"cosine\"},\n",
    "            \"grid\": {\"min\": -1.0, \"max\": 1.0, \"sigma\": 0.02, \"n\": 30},\n",
    "            \"weighting\": {\"function\": \"exp\", \"scale\": 1.0, \"threshold\": 1e-3},\n",
    "        },\n",
    "        flatten=True,\n",
    "        normalization=\"n_atoms\",\n",
    "        sparse=False)\n",
    "    onevec = mbtr.create(mpdata[i])\n",
    "    mbtr_lists.append(onevec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1267d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "for i in range(len(mbtr_lists)):\n",
    "    sizes.append(len(mbtr_lists[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db483d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeropadding_mbtrlists = []\n",
    "\n",
    "for i in range(len(mbtr_lists)):\n",
    "    zeros = np.zeros(max(sizes)-len(mbtr_lists[i]))\n",
    "    one = np.append(mbtr_lists[i], zeros)\n",
    "    zeropadding_mbtrlists.append(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set our seed and other configurations for reproducibility\n",
    "\n",
    "seed = 42\n",
    "#42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensors = []\n",
    "\n",
    "for i in range(len(zeropadding_mbtrlists)):\n",
    "    new_tensors.append(th.tensor(zeropadding_mbtrlists[i]))\n",
    "\n",
    "new_t = th.stack(new_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17829614",
   "metadata": {},
   "outputs": [],
   "source": [
    "arry = np.ones(len(new_t))\n",
    "\n",
    "labels = th.from_numpy(arry)\n",
    "labels = labels.clone().detach()\n",
    "#labels = th.tensor(labels, dtype=torch.float32)\n",
    "labels = labels.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bace07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(new_t, labels)\n",
    "#train_dataset = torch.utils.data.TensorDataset(train_tensor, train_label)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdim = len(new_t[1])\n",
    "second = 100\n",
    "#embdim = 100\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(inputdim, second)\n",
    "        #self.fc2 = nn.Linear(second, embdim)\n",
    "        #self.fc3 = nn.Linear(embdim, second)\n",
    "        self.fc4 = nn.Linear(second, inputdim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        #return torch.relu(self.fc2(h1))\n",
    "        return h1\n",
    "\n",
    "    def decode(self, z):\n",
    "        #h3 = F.relu(self.fc3(z))\n",
    "        #return torch.relu(self.fc4(h3))\n",
    "        return torch.relu(self.fc4(z))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, inputdim))\n",
    "        #z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z)\n",
    "\n",
    "\n",
    "model = AE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = my_loss()\n",
    "#criterion = nn.L1Loss()\n",
    "#criterion = MAPE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340089b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "epochs = 20\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for data, labels in trainloader:\n",
    "        # Transfer Data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target.float(),data.float())\n",
    "        #loss = my_loss(target.float(),data.float())\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    #valid_loss = 0.0\n",
    "    #model.eval()     # Optional when not using Model Specific layer\n",
    "    #for data, labels in validloader:\n",
    "    #    # Transfer Data to GPU if available\n",
    "    #    if torch.cuda.is_available():\n",
    "    #        data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # Forward Pass\n",
    "    #    target = model(data.float())\n",
    "    #    # Find the Loss\n",
    "    #    loss = criterion(target.float(),labels.float())\n",
    "    #    # Calculate Loss\n",
    "    #    valid_loss += loss.item()\n",
    "\n",
    "    #print(train_loss / len(trainloader), valid_loss / len(validloader))\n",
    "    print(train_loss / len(trainloader))\n",
    "    \n",
    "    #if min_valid_loss > valid_loss:\n",
    "    #    print(min_valid_loss, 'Saving The Model')\n",
    "    #    min_valid_loss = valid_loss\n",
    "\n",
    "        # Saving State Dict\n",
    "    #torch.save(model.state_dict(), '30-ae_hv_saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    testlosslist = []\n",
    "    with torch.no_grad():\n",
    "        for test_batch, _ in dataloader:\n",
    "            test_batch = test_batch.view(-1, len(new_t[1])).to(device)\n",
    "            pred = model(test_batch.float())\n",
    "            testloss = criterion(pred.float(), test_batch.float())\n",
    "            testlosslist.append(testloss.item())\n",
    "            #test_loss += testloss.item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    #test_loss /= size\n",
    "    #correct /= size\n",
    "    #print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    #testlosslist=[]\n",
    "    #testlosslist.append(test_loss)\n",
    "    return testlosslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arry = np.ones(len(new_t))\n",
    "\n",
    "labels = th.from_numpy(arry)\n",
    "labels = labels.clone().detach()\n",
    "#labels = th.tensor(labels, dtype=torch.float32)\n",
    "labels = labels.view(-1, 1)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(new_t, labels)\n",
    "alldataloader_eval = torch.utils.data.DataLoader(all_dataset, batch_size=1)\n",
    "alllosses = evaluate(alldataloader_eval, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2a242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce661ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
